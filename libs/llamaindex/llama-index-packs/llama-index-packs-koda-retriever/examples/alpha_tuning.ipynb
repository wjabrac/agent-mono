{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Tuning w/ Koda Retriever\n",
    "\n",
    "*For this example non-production ready infrastructure is leveraged*\n",
    "More specifically, the default sample data provided in a free start instance of [Pinecone](https://www.pinecone.io/) is used. This data consists of movie scripts and their summaries embedded in a free Pinecone vector database.\n",
    "\n",
    "### Agenda\n",
    "- Fixture Setup\n",
    "- Alpha Tuning Setup\n",
    "- Koda Retriever: Retrieval \n",
    "\n",
    "A quick overview/visual on how alpha tuning works: (excuse the weird colors, my color settings on Windows was weirdly interacting w/ Google Sheets and made some colors useless)\n",
    "![alpha-tuning](https://i.imgur.com/zxCXqGb.png)\n",
    "\n",
    "### Example Context\n",
    "Let's say you're building a query engine or agent that is expected to answer questions on Deep Learning, AI, RAG Architecture, and adjacent topics. As a result of this, your team has narrowed down three main query classifications and associated alpha values with those classifications. Your alpha values were determined by incrementally decreasing the alpha value from 1 to 0 and for each new alpha value, several queries are run and evaluated. Repeating this process for each category should yield an optimal alpha value for each category over your data. This process should be repeated periodically as your data expands or changes. \n",
    "\n",
    "With the categories and corresponding alpha values uncovered, these are our categories:\n",
    "- Concept Seeking Queries *(α: 0.2)*\n",
    "- Fact Seeking Queries *(α: .6)*\n",
    "- Queries w/ Misspellings *(α: 1)*\n",
    "\n",
    "Clearly, these categories have very different biases towards one end of the retrieval spectrum. The default for Llama Index hybrid retrievers is 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary modules\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.postprocessor import LLMRerank\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.packs.koda_retriever import KodaRetriever\n",
    "import os\n",
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Building *required objects* for a Koda Retriever.\n",
    "- Vector Index\n",
    "- LLM/Model\n",
    "\n",
    "Other objects are *optional*, and will be used if provided:\n",
    "- Reranker\n",
    "- Custom categories & corresponding alpha weights\n",
    "- A custom model trained on the custom info above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index(\"sample-movies\")\n",
    "\n",
    "Settings.llm = OpenAI()\n",
    "Settings.embed_model = OpenAIEmbedding()\n",
    "\n",
    "vector_store = PineconeVectorStore(pinecone_index=index, text_key=\"summary\")\n",
    "vector_index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=Settings.embed_model\n",
    ")\n",
    "\n",
    "reranker = LLMRerank(llm=Settings.llm)  # optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Categories & Alpha Values\n",
    "\n",
    "We need to first input our categories and alpha values in a format that Koda can understand.\n",
    "\n",
    "### Important Considerations:\n",
    "If you provide these custom categories and no custom model, these values will be input as few-shot context training for whatever model is provided to Koda Retriever. Otherwise, if a custom model is provided and has been trained on the data that would otherwise be provided below, ensure the keys of the categories dictionary matches the expected labels of the custom model. Likewise, do NOT provide any examples or a description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is easiest and recommended to define your alpha categories and values in a dictionary\n",
    "# It must follow this format:\n",
    "# {\n",
    "#     \"category_name\": {\n",
    "#         \"alpha\": 0.5,  # alpha value - always required\n",
    "#         \"description\": \"description of the category\", # optional if providing fine tuned model\n",
    "#         \"examples\": [ # optional if providing fine tuned model\n",
    "#             \"example 1\", # provide at least 1 example\n",
    "#             \"example 2\"\n",
    "#         ]\n",
    "\n",
    "categories = {  # key, #alpha, description [and examples]\n",
    "    \"concept seeking query\": {\n",
    "        \"alpha\": 0.2,\n",
    "        \"description\": \"Abstract questions, usually on a specific topic, that require multiple sentences to answer\",\n",
    "        \"examples\": [\n",
    "            \"What is the dual-encoder architecture used in recent works on dense retrievers?\",\n",
    "            \"Why should I use semantic search to rank results?\",\n",
    "        ],\n",
    "    },\n",
    "    \"fact seeking query\": {\n",
    "        \"alpha\": 0.6,\n",
    "        \"description\": \"Queries with a single, clear answer\",\n",
    "        \"examples\": [\n",
    "            \"What is the total number of propositions the English Wikipedia dump is segmented into in FACTOID WIKI?\",\n",
    "            \"How many documents are semantically ranked?\",\n",
    "        ],\n",
    "    },\n",
    "    \"queries with misspellings\": {\n",
    "        \"alpha\": 1,\n",
    "        \"description\": \"Queries with typos, transpositions and common misspellings introduced\",\n",
    "        \"examples\": [\n",
    "            \"What is the advntage of prposition retrieval over sentnce or passage retrieval?\",\n",
    "            \"Ho w mny documents are samantically r4nked\",\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Koda Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = KodaRetriever(\n",
    "    index=vector_index,\n",
    "    llm=Settings.llm,\n",
    "    matrix=categories,  # koda now knows to use these categories\n",
    "    reranker=reranker,  # optional\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving w/ Koda Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='33', embedding=None, metadata={'box-office': 1113138548.0, 'title': 'Jurassic Park', 'year': 1993.0}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='A theme park showcasing genetically engineered dinosaurs turns into a nightmare when the creatures escape their enclosures, forcing the visitors to fight for survival.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=8.0),\n",
       " NodeWithScore(node=TextNode(id_='7', embedding=None, metadata={'box-office': 1671537444.0, 'title': 'Jurassic World', 'year': 2015.0}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Set in a fully functioning dinosaur theme park on Isla Nublar, Jurassic World faces chaos when a genetically engineered dinosaur, the Indominus Rex, escapes. Stars Chris Pratt and Bryce Dallas Howard.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=7.0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Can you explain the Jurassic Park as a business as it was supposed to operate inside the movie's lore or timeline?\"\n",
    "results = retriever.retrieve(query)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those results don't look quite palletteable though. For that, lets look into making the response more *natural*. For that we'll likely need a Query Engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Engine w/ Koda Retriever\n",
    "\n",
    "Query Engines are [Llama Index abstractions](https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/root.html) that combine retrieval and synthesization of an LLM to interpret the results given by a retriever into a natural language response to the original query. They are themselves an end-to-end pipeline from query to natural langauge response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Jurassic Park was intended to be a theme park that featured genetically engineered dinosaurs as its main attraction. Visitors were meant to experience the thrill of seeing these creatures up close in a controlled environment. However, due to unforeseen circumstances in the movie's storyline, the dinosaurs escaped their enclosures, leading to chaos and danger for the visitors.\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine = RetrieverQueryEngine.from_args(retriever=retriever)\n",
    "\n",
    "response = query_engine.query(query)\n",
    "\n",
    "str(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
